// Example stub, replace with your llama.cpp or local LLaMA call
export const runLlama = async (prompt) => {
  // In reality, spawn a child process to run your local LLaMA binary
  console.log("Running LLaMA on:", prompt);
  return `Mock answer for: "${prompt}"`;
};
